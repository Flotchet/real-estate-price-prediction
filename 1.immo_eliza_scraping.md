# Collecting Data

- Repository: `real-estate-price-prediction`
- Type of Challenge: `Consolidation`
- Duration: `5 days`
- Deadline: `06/01/2023 04:00 PM`
- Challenge : Team

## Learning objectives

Use a Python library to collect as much data as possible.

At the end of this challenge, you should :

- Be able to scrape a website.
- Be able to build a dataset from scratch
- Be able to implement a strategy to collect as much data as possible

## The Mission

As you know the real estate company "ImmoEliza" wants to create a Machine Learning model to make price predictions on real estate sales in Belgium.

In that mission your first task is to build a dataset gathering information about at least 10,000 properties all over Belgium. This dataset will be used later as a training set for your prediction model.

This dataset should be a `csv` file with the following columns:

- Locality
- Type of property (House/apartment)
- Subtype of property (Bungalow, Chalet, Mansion, ...)
- Price
- Type of sale (Exclusion of life sales)
- Number of rooms
- Living Area
- Fully equipped kitchen (Yes/No)
- Furnished (Yes/No)
- Open fire (Yes/No)
- Terrace (Yes/No)
  - If yes: Area
- Garden (Yes/No)
  - If yes: Area
- Surface of the land
- Surface area of the plot of land
- Number of facades
- Swimming pool (Yes/No)
- State of the building (New, to be renovated, ...)

### Must-have features

- Data all over Belgium.
- Minimum 10,000 inputs without duplicates
- No empty row. If you are missing information, set the value to `None`.
- The dataset must be clean. Try as much as possible to record only numerical values.
  **Example**: Instead of defining whether the kitchen is equipped using `"Yes"`, use binary values.

### Some tips and content to support you

- You will find more content about scraping [here](../../2.python/2.python_advanced/05.Scraping/)
- Think to [pandas](../../3.data_tools/pandas/) for creating and exporting your dataset
- Use concurrency [concurrency](../../2.python/2.python_advanced/06.Concurrency/) to increase the speed of data collection
- You might have to work around CAPTCHA and other measures to slow you down. Be creative ;)
- Use a virtual environment for the project and add a `.gitignore` file to your repository

## Deliverables

1. Publish your source code on the GitHub repository of your project in a folder named `data_acquisition`.
2. Start writing your README file:
   - Description
   - Installation
   - Usage
   - (Visuals)
   - (Contributors)
   - (Timeline)
   - (Personal situation)

### Steps

1. Create the repository `real-estate-price-prediction` and add a folder `data_acquisition`
2. Study the request (What & Why ?)
3. Identify technical challenges (How ?)

## Evaluation criteria

| Criteria       | Indicator                                  | Yes/No |
| -------------- | ------------------------------------------ | ------ |
| 1. Is complete | Contains a minimum of 10,000 inputs.       | [ ]    |
|                | Contains data for all of Belgium.          | [ ]    |
|                | No empty row present in the dataset.       | [ ]    |
|                | Non-numeric values have been minimized.    | [ ]    |
| 2. Is great    | Used threading to speed up the collection. | [ ]    |

## A final note of encouragement

_Attempts to create thinking machines will be a great help in discovering how we think ourselves._
_- Alan Turing_

![You've got this!](https://i.giphy.com/media/JWuBH9rCO2uZuHBFpm/giphy.gif)
